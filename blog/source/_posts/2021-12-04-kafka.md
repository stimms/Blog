The difference between Kafka and another queuing system like RabbitMQ or Azure Service Bus is that Kafka allows for retaining messages for a set period of time independently of the consumers. Perhaps an example will help illustrate that. 

Here we have a time-line of events and consumers subscribing to a series of events. In this case we have all the events fired when a user is added. 

![Time line showing consumers and messages on a topic](../images/kafka/2021-12-04-15-51-05.png)

If this topic was an ASB topic then the messages received by the subscribers would be 

```
Consumer 0 -> Bob Added, Alice Added, Candice Added
Consumer 1 -> Alice Added, Candice Added
Consumer 2 -> Candice Added
```

A consumer will only get messages which were published after the consumer subscribed. However if this was a Kafka topic then the consumers would get 

```
Consumer 0 -> Bob Added, Alice Added, Candice Added
Consumer 1 -> Bob Added, Alice Added, Candice Added
Consumer 2 -> Bob Added, Alice Added, Candice Added
```

The consumer would get messages from the start of the stream, or at least the start of the retention period, on. Why would you want that? Well if you were trying to build a system that built read models based on the event stream you'd be able to replay it from the start of time and get an accurate model at any point in the future. 

This is perhaps not quite the exact same thing as Event Sourcing depending on your definition but it at the very least Event Sourcing adjacent. I cannot tell you the number of times over the years that I've run into production issues where having a complete event log would have made my life easier. "Simon, who deleted this user?" "Simon, when did we make this change to accounts?" or, worst of all "How come this data has value `A` and not `B`?"

# Partitions and Topics 

Kafka is designed to be used in very busy environments with bucket loads of messages going around the system every day. This is more than can be handled by any single server